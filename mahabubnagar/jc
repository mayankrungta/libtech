#! /usr/bin/env python

#This code will get the Oabcgatat Banes
import os
import csv
from bs4 import BeautifulSoup
import requests

import logging
import MySQLdb
import time
import re

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.by import By

#######################
# Global Declarations
#######################

delay = 2
timeout = 10
url="http://www.nrega.telangana.gov.in/"
browser="Firefox"
logFile = 'jc.log'
logLevel = logging.ERROR
logFormat = '%(asctime)s:[%(name)s|%(levelname)s]: %(message)s'

# Error File Defination
errorfile = open('./logs/jc.log', 'w')


#############
# Functions
#############

'''
def logInitialize():
  import logging
  logging.basicConfig(filename=logFile, level=logLevel, format=logFormat) # Mynk
'''

def loggerFetch(level='ERROR'):
  logger = logging.getLogger(__name__)

  if level:                     # Mynk ???
    numeric_level = getattr(logging, level.upper(), None)
    if not isinstance(numeric_level, int):
      raise ValueError('Invalid log level: %s' % level)
    else:
      logger.setLevel(numeric_level)
  else:
    logger.setLevel(logLevel)

  # create console handler and set level to debug
  ch = logging.StreamHandler()
  ch.setLevel(logging.DEBUG)    # Mynk ???

  # create formatter e.g - FORMAT = '%(asctime)-15s %(clientip)s %(user)-8s %(message)s'
  formatter = logging.Formatter(logFormat)

  # add formatter to ch
  ch.setFormatter(formatter)

  # add ch to logger
  logger.addHandler(ch)

  return logger

def loggerTest(logger):
  logger.debug('debug message')
  logger.info('info message')
  logger.warn('warn message')
  logger.error('error message')
  logger.critical('critical message')
    

def argsFetch():
  '''
  Paser for the argument list that returns the args list
  '''
  import argparse

  parser = argparse.ArgumentParser(description='Jobcard script for crawling, downloading & parsing')
  parser.add_argument('-c', '--crawl', help='Crawl the jobcards numbers and populate database', required=False, action='store_const', const=True)
  parser.add_argument('-d', '--download', help='Download the jobcards & musters for each jobcard ID', required=False, action='store_const', const=True)
  parser.add_argument('-p', '--parse', help='Parse the jobcards & musters downloaded', required=False, action='store_const', const=True)
  parser.add_argument('-v', '--visible', help='Make the browser visible', required=False, action='store_const', const=1)
  #parser.add_argument('-d', '--debug', help='Debug level (default=)', required=False)
  parser.add_argument('-l', '--log-level', help='Log level defining verbosity', required=False)
  parser.add_argument('-t', '--timeout', help='Time to wait before a page loads', required=False)
  parser.add_argument('-b', '--browser', help='Specify the browser to test with', required=False)
  parser.add_argument('-u', '--url', help='Specify the url to crawl', required=False)

  args = vars(parser.parse_args())
  return args


def parserFinalize(parser):
  parser.close()


def dbInitialize():
  '''
  Connect to MySQL Database
  '''
  db = MySQLdb.connect(host="localhost", user="root", passwd="root123", db="mahabubnagar")
  db.autocommit(True)
  return db;

def dbFinalize(db):
  db.close()

def displayInitialize(isVisible=0):
  from pyvirtualdisplay import Display
  
  display = Display(visible=isVisible, size=(600, 400))
  display.start()
  return display

def displayFinalize(display):
  display.stop()

def driverInitialize(browser="Firefox"):
  if browser == "Firefox":
    fp = webdriver.FirefoxProfile()
    fp.native_events_enabled = False
    fp.set_preference("browser.download.folderList",2)
    fp.set_preference("browser.download.manager.showWhenStarting",False)
    fp.set_preference("browser.download.dir", os.getcwd())
    fp.set_preference("browser.helperApps.neverAsk.saveToDisk", "application/vnd.ms-excel")

    driver = webdriver.Firefox(fp)
  elif browser == "PhantomJS":
    driver = webdriver.PhantomJS()
    driver.set_window_size(1120, 550)
  else:
    driver = webdriver.Chrome()

  driver.implicitly_wait(10)

  return driver

def driverFinalize(driver):
  driver.close()


def wdTest(driver):
  driver.get("http://www.google.com")
  print driver.page_source.encode('utf-8')


def wdFetch(driver, logger):
  driver.get(url)

  elem = driver.find_element_by_link_text("Wage Seekers")
  elem.send_keys(Keys.RETURN)
  time.sleep(1)

  elem = driver.find_element_by_link_text("Job Card Holders Information")
  elem.send_keys(Keys.RETURN)
  time.sleep(1)

  elem = driver.find_element_by_name("District")
  elem.send_keys("Mahabubnagar")
  elem.send_keys(Keys.RETURN)
  #elem.click()
  time.sleep(delay)

  elem = driver.find_element_by_name("Mandal")
  elem.send_keys("Ghattu")
  elem.send_keys(Keys.RETURN)
  #elem.click()
  time.sleep(delay)

  return driver


def wdFetchPanchayat(driver, cur, logger, panchayatName):
  elem = driver.find_element_by_name("Go")
  elem.send_keys(Keys.RETURN)

  curtime = time.strftime('%Y-%m-%d %H:%M:%S')
  html_source = driver.page_source
  htmlsoup=BeautifulSoup(html_source)
  try:
    table=htmlsoup.find('table',id="sortable")
    rows = table.findAll('tr')
    td = table.find('td')
    #print "DATA[", td.text, "]"
   # #print rows
    status=1
  except:
    status=0
  # query="update panchayats set jobcardCrawlStatus="+str(status)+", jobcardCrawlDate='"+curtime+"' where id="+str(panchID) # Update downloadStatus at the end
  # #print query
  # cur.execute(query)

  jcDownloaded = os.listdir('./musters')
  
  if status==1:
    for tr in rows:
      td = tr.findNext('td')
      #print "DATA1[", td.text, "]"
      td = td.findNext('td')
      #print "DATA2[", td.text, "]"
      jcno = td.text.strip()
      #print "jcno", jcno
      #if jcno+'.xls' in jcDownloaded:
      #if jcno+'.html' in jcDownloaded:
      if jcno+'.csv' in jcDownloaded:
        continue

      '''
      try:
        elem = WebDriverWait(driver, timeout).until(
          EC.presence_of_element_located((By.LINK_TEXT, jcno))
        )
        #elem = WebDriverWait(driver, delay).until(EC.presence_of_element_located(driver.find_element_by_link_text(jcno)))
        print "Page is ready!"
        #except TimeoutException:
      except NoSuchElementException, TimeoutException:
        print "Loading took too much time!"
        continue

      #elem = driver.find_element_by_link_text(jcno)
      #elem.send_keys(Keys.RETURN)
      elem.click()
      time.sleep(delay)
      '''
      
      if True:
        elem = driver.find_element_by_link_text(jcno)
        elem.send_keys(Keys.RETURN)
        time.sleep(1)

      parent_handle = driver.current_window_handle
      print "Handles : ", driver.window_handles, "Number : ", len(driver.window_handles)

      

      if len(driver.window_handles) == 2:
        driver.switch_to_window(driver.window_handles[-1])
      else:
        logger.error("Handlers gone wrong [" + str(driver.window_handles) + "]")
        driver.save_screenshot('./logs/button_'+jcno+'.png')
        continue

      #jc_html=driver.page_source.encode('utf-8')
      #jcsource = driver.page_source

      #os.rename('Muster*', './musters/')

      # Download the muster details
      try:
        elem = WebDriverWait(driver, timeout).until(
          EC.presence_of_element_located((By.ID, "sortable"))
        )
        driver.find_element_by_name("Go").click()
      except NoSuchElementException, TimeoutException:
          logger.error("Failed to locate Muster Roll Button")
          driver.save_screenshot('./logs/button_'+jcno+'.png')
          driver.close()
          driver.switch_to_window(parent_handle)
          continue

      if False:
        # Download the html file for parsing later
        html_file = open('./musters/'+jcno+'.html', 'w') # Mynk
        html_file.write(jc_html)
        html_file.close

      #myhtml = jcsource.replace('<head>','<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>')
      #htmlDump = myhtml.encode("UTF-8")

      
      retries = 0
      while not os.path.isfile('Muster'):
        time.sleep(delay)
        retries += 1
        if retries > 10:
          logger.error("Timed out waiting for Muster excel")
          driver.save_screenshot('./logs/download_wait_'+jcno+'.png')
          driver.close()
          driver.switch_to_window(parent_handle)
          continue

      if False:
        #os.rename('Muster', './musters/'+jcno+'.xls')
        cmd = 'libreoffice --headless --convert-to csv Muster --outdir musters'
        os.system(cmd)
        os.rename('./musters/Muster.csv', './musters/'+jcno+'.xls')
        os.system('rm Muster')
      else:
        cmd = 'ssconvert Muster ./musters/'+jcno+'.csv'
        os.system(cmd)
        os.system('rm Muster')
      
      driver.close()
      driver.switch_to_window(parent_handle)
      '''
      #print "HTML[", jc_html, "]"
      query="insert into jobcardDump (jobcard, htmlDump) values ('"+jcno+"','"+jc_html+"')"
      cur.execute(query)
      '''
      query="update jobcardRegister set isProcessed=1 where jobcard='"+jcno+"'"
      cur.execute(query)

def dbFetch(db, logger):
  # Query to get all the blocks
  query="select stateCode,districtCode,blockCode,name from blocks"
  logger.info('query: [%s]', query)
  cur=db.cursor()
  cur.execute(query)
  results = cur.fetchall()
  logger.info('results: [%s]', str(results))

  return results


def crawlJobcards(driver, db, logger):
  '''
  Crawl the page for the jobcards and update them in the database
  '''
  driver = wdFetch(driver, logger)

  query="select stateCode,districtCode,blockCode,name from blocks"
  logger.info('query: [%s]', query)
  cur=db.cursor()
  cur.execute(query)
  results = cur.fetchall()
  logger.info('results: [%s]', str(results))

  # results = dbFetch(db, logger)

  for row in results:
    stateCode=row[0]
    districtCode=row[1]
    blockCode=row[2]
    blockName=row[3]

  query="select name,panchayatCode,id from panchayats where jobcardCrawlStatus=0 and stateCode='"+stateCode+"' and districtCode='"+districtCode+"' and blockCode='"+blockCode+"' "
  cur.execute(query)
  panchresults = cur.fetchall()
  #print panchresults

  for panchrow in panchresults:
    panchayatName=panchrow[0]
    panchayatCode=panchrow[1]
    panchID=panchrow[2]
    #print stateCode+districtCode+blockCode+blockName+panchayatCode+panchayatName
    elem = driver.find_element_by_name("Panchayat")
    elem.send_keys(panchayatName)
    elem.send_keys(Keys.RETURN)
    #elem.click()
    time.sleep(delay)

    elem = driver.find_element_by_name("Go")
    elem.send_keys(Keys.RETURN)
    
    curtime = time.strftime('%Y-%m-%d %H:%M:%S')
    html_source = driver.page_source
    htmlsoup=BeautifulSoup(html_source)
    try:
      table=htmlsoup.find('table',id="sortable")
      rows = table.findAll('tr')
      td = table.find('td')
      #print "DATA[", td.text, "]"
     # #print rows
      status=1
    except:
      status=0
    query="update panchayats set jobcardCrawlStatus="+str(status)+", jobcardCrawlDate='"+curtime+"' where id="+str(panchID) 
    # #print query
    cur.execute(query)
    if status==1:
      for tr in rows:
        td = tr.findNext('td')
        #print "DATA1[", td.text, "]"
        td = td.findNext('td')
        #print "DATA2[", td.text, "]"
        jcno = td.text.strip()
        #print "jcno", jcno
        td = td.findNext('td')
        #print "DATA3[", td.text, "]"
        gjcno = td.text.strip()
        #print "gjcno", gjcno
        td = td.findNext('td')
        #print "DATA4[", td.text, "]"
        hof = td.text
        #print "HOF", hof
        td = td.findNext('td')
        regDate = td.text
        #print "Reg Date", regDate
        issueDate = "STR_TO_DATE('"+regDate+"','"+"%d/%m/%Y')"
        td = td.findNext('td')
        caste = td.text
        #print "caste", caste
                        
        if True:
          #print jcno
          query="insert into jobcardRegister (jobcard,govtJobcard,stateCode,headOfFamily,issueDate,caste,districtCode,blockCode,panchayatCode) values ('"+jcno+"','"+gjcno+"','"+stateCode+"','"+hof+"',"+issueDate+",'"+caste+"','"+districtCode+"','"+blockCode+"','"+panchayatCode+"')"
          #print "<<", query, ">>"
          try:
            cur.execute(query)
          except MySQLdb.IntegrityError,e:
            errormessage=(time.strftime("%d/%m/%Y %H:%M:%S "))+str(e)+"\n"
            errorfile.write(errormessage)
          continue

    time.sleep(delay)

  time.sleep(delay)


def downloadJobcards(driver, db, logger):
  '''
  Crawl the page for the jobcards and update them in the database
  '''
  wdFetch(driver, logger)

  if False:
    results = dbFetch(db, logger)
    cur=db.cursor()

  cur=db.cursor()

  query="select j.stateCode,j.districtCode,j.blockCode,j.panchayatCode,p.name,b.name from jobcardRegister j, panchayats p, blocks b where j.blockCode=p.blockCode and j.panchayatCode=p.panchayatCode and j.blockCode=b.blockCode and j.isProcessed=0 group by j.blockCode,j.panchayatCode"  # Mynk
  print query
  cur.execute(query)
  print "count: ", cur.rowcount
  if cur.rowcount:
    results = cur.fetchall()
    print "Data:", results
    for row in results:
      stateCode=row[0]
      districtCode=row[1]
      blockCode=row[2]
      panchayatCode=row[3]
      panchayatName=row[4]
      blockName=row[5]
      print panchayatName, blockName 

      wdFetchPanchayat(driver, cur, logger, panchayatName)

  if False:
      query="select jobcard from jobcardRegister where isDownloaded=0 and stateCode='"+stateCode+"' and districtCode='"+districtCode+"' and blockCode='"+blockCode+"' and panchayatCode='"+panchayatCode+"' limit 50"
      cur.execute(query)
      jcresults = cur.fetchall()
      for jcrow in jcresults:
        jobcard=jcrow[0]
        i=i+1
        print str(i)+"  "+jobcard
        elem = driver.find_element_by_link_text(jobcard)
        elem.send_keys(Keys.RETURN)
        time.sleep(5)
        jcsource = driver.page_source
        driver.back()
        time.sleep(2)
        myhtml=jcsource.replace('<head>','<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>')
        jcfilename=jcfilepath+blockName+"/"+panchayatName.upper()+"/jobcardRegister/"+jobcard.replace("/","_")+".html"
        if not os.path.exists(os.path.dirname(jcfilename)):
          os.makedirs(os.path.dirname(jcfilename))
        myfile = open(jcfilename, "w")
        myfile.write(myhtml.encode("UTF-8"))
        query="update jobcardRegister set isDownloaded=1 where jobcard='"+jobcard+"'"
        cur.execute(query)
        # End of Dead IF

      time.sleep(delay)
  time.sleep(delay)


def downloadJobcardsViaBruteForce(driver, db, logger):
  '''
  Crawl the page for the jobcards and update them in the database
  '''
  wdFetch(driver, logger)

  results = dbFetch(db, logger)
  cur=db.cursor()

  for row in results:
    stateCode=row[0]
    districtCode=row[1]
    blockCode=row[2]
    blockName=row[3]

  query="select name,panchayatCode,id from panchayats where stateCode='"+stateCode+"' and districtCode='"+districtCode+"' and blockCode='"+blockCode+"' "
  #print query
  cur.execute(query)
  panchresults = cur.fetchall()
  #print panchresults

  for panchrow in panchresults:
    panchayatName=panchrow[0]
    panchayatCode=panchrow[1]
    panchID=panchrow[2]
    #print stateCode+districtCode+blockCode+blockName+panchayatCode+panchayatName

    wdFetchPanchayat(driver, cur, logger, panchayatName)

    time.sleep(delay)
  time.sleep(delay)

def extractJobcards(db):
  cur=db.cursor()

  query="select jobcard from jobcardRegister where panchayatCode=003"
  print query
  cur.execute(query)
  jcs = cur.fetchall()
  jobcards = map(list, jcs)
  #print jobcards

  for jc in jobcards:
    jcno = str(jc).strip('[]')
    print "Moving ", jc, jcno
    #exit(-1)
    cmd = 'cp -v ./musters/'+jcno+'.* ./musters/Thumalacheruvu/'
    print cmd
    os.system(cmd)


def main():
  args = argsFetch()
  logger = loggerFetch(args.get('log_level'))        # Mynk WTF is '_' doing here?
  # loggerTest(logger)
  logger.info('args: %s', str(args))

  db = dbInitialize()
  display = displayInitialize(args['visible'])
  driver = driverInitialize(browser)

#  wdTest(driver)

  if args['crawl']:
    crawlJobcards(driver, db, logger)
  else:
    downloadJobcards(driver, db, logger)
    # wdTest(driver)
    # extractJobcards(driver, db, logger)

  driverFinalize(driver)
  displayFinalize(display)
  dbFinalize(db)
  exit(0)

if __name__ == '__main__':
  main()

